{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae118e91-8b86-4890-bd37-2cf7ec96226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "is_kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4881ad8-8517-4954-809e-7045ec4619aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "cred_path = Path('~/.kaggle/kaggle.json').expanduser()\n",
    "if not cred_path.exists():\n",
    "    creds = '{\"username\":\"aspiringastronomer\",\"key\":\"042f3b9ca8ccb28a6f804d983fa39a29\"}'\n",
    "    cred_path.parent.mkdir(exist_ok=True)\n",
    "    cred_path.write_text(creds)\n",
    "    cred_path.chmod(0o600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49dc45b7-0263-4f9d-876c-7ca8135b5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('us-patent-phrase-to-phrase-matching') # us-patent-phrase-to-phrase-matching\n",
    "if not is_kaggle and not path.exists():\n",
    "    !pip install -Uqq kaggle\n",
    "    import zipfile, kaggle\n",
    "    \n",
    "    kaggle.api.competition_download_cli(str(path))\n",
    "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8724e428-b17c-4666-8914-fe633818a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577f8fda-bf6c-41c4-8c39-c62fa926fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7fd537-be90-4116-a868-49e761958556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09e12f3-e9d4-40c8-840c-ba1d58848a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20ce46c-eda7-4c99-a686-acfcfe12a2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n",
       "1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n",
       "2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n",
       "3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n",
       "4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'] = \"TEXT1: \" + df.context + \"; TEXT2: \" + df.target + \"; ANC1: \" + df.anchor\n",
    "df.input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79dfb683-43cb-436e-9547-6ffc35ac3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d99d069-694b-474f-a8b8-54715cb356ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b0037c-617b-4716-8fbc-dc9afa24b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A deep learning model expects numbers as inputs, not English sentences! So we need to do two things:\n",
    "\n",
    "# - Tokenization: Split each text up into words (or actually, as we'll see, into tokens)\n",
    "# - Numericalization: Convert each word (or token) into a number.\n",
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690413d5-b57b-4137-9ccc-f1291222aae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2eaca172e3a44c68ea1b83d325d44c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd0a678449d4070bde0eb8920b5525d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0644eec89fbe4bf6839ff6dbf1676a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d515cf38-40b4-4b27-ad1b-5545e79076a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Day',\n",
       " '▁1',\n",
       " '▁of',\n",
       " '▁365',\n",
       " '▁-',\n",
       " '▁Learn',\n",
       " '.',\n",
       " '▁Build',\n",
       " '.',\n",
       " '▁It',\n",
       " 'erate',\n",
       " '!',\n",
       " '▁Attention',\n",
       " '▁is',\n",
       " '▁all',\n",
       " '▁you',\n",
       " '▁need',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"Day 1 of 365 - Learn. Build. Iterate! Attention is all you need.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eddf626-49ba-44d4-aaa1-902efe0f86e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁The',\n",
       " '▁blue',\n",
       " '▁whale',\n",
       " '▁(',\n",
       " 'B',\n",
       " 'ala',\n",
       " 'en',\n",
       " 'optera',\n",
       " '▁musc',\n",
       " 'ulus',\n",
       " ')',\n",
       " '▁is',\n",
       " '▁a',\n",
       " '▁marine',\n",
       " '▁mammal',\n",
       " '▁and',\n",
       " '▁a',\n",
       " '▁bale',\n",
       " 'en',\n",
       " '▁whale',\n",
       " '.',\n",
       " '▁Reaching',\n",
       " '▁a',\n",
       " '▁maximum',\n",
       " '▁confirmed',\n",
       " '▁length',\n",
       " '▁of',\n",
       " '▁29',\n",
       " '.',\n",
       " '9',\n",
       " '▁meters',\n",
       " '▁and',\n",
       " '▁weighing',\n",
       " '▁up',\n",
       " '▁to',\n",
       " '▁199',\n",
       " '▁tonnes',\n",
       " ',',\n",
       " '▁it',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁largest',\n",
       " '▁animal',\n",
       " '▁known',\n",
       " '▁to',\n",
       " '▁have',\n",
       " '▁ever',\n",
       " '▁existed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"The blue whale (Balaenoptera musculus) is a marine mammal and a baleen whale. Reaching a maximum confirmed length of 29.9 meters and weighing up to 199 tonnes, it is the largest animal known to have ever existed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c288fc44-3799-48eb-bac0-7f269e5fe459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139d410f-fe0a-4225-9aed-9a3cd66b3422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac09736de6d43558b01519351fce02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)\n",
    "# This adds a new item to our dataset called input_ids. For instance, here is the input and IDs for the first row of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aabea432-2124-4baa-9def-2f29334f47df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement'],\n",
       " [[1,\n",
       "   54453,\n",
       "   435,\n",
       "   294,\n",
       "   336,\n",
       "   5753,\n",
       "   346,\n",
       "   54453,\n",
       "   445,\n",
       "   294,\n",
       "   47284,\n",
       "   265,\n",
       "   6435,\n",
       "   346,\n",
       "   23702,\n",
       "   435,\n",
       "   294,\n",
       "   47284,\n",
       "   2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds = tok_ds.rename_columns({'score':'labels'})\n",
    "rows = tok_ds[:1]\n",
    "rows['input'], rows['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede16f67-ff60-45ca-bcd8-480d67513fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>el display</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id      anchor                         target context\n",
       "count                 36          36                             36      36\n",
       "unique                36          34                             36      29\n",
       "top     4112d61851461f60  el display  inorganic photoconductor drum     G02\n",
       "freq                   1           2                              1       3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(path/'test.csv')\n",
    "eval_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6233e5-7ad2-428b-9f94-e66dd5648afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target context\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n",
       "2  36baf228038e314b      lower trunnion                 lower locating     B60\n",
       "3  1f37ead645e7f0c8       cap component                  upper portion     D06\n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86af6d4-e44e-4913-be30-a3f2216343be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1866b8f-9e11-44ca-bead-2f9688faec2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5273ca262047eca81d88f603eb6496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79096d35-a5f2-4aee-82fe-44af012dd68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "177d8913-468e-4338-9e4c-6e5c7c5f38f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "\n",
    "def show_corr(df, a, b):\n",
    "    x,y = df[a],df[b]\n",
    "    plt.scatter(x,y, alpha=0.5, s=4)\n",
    "    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')\n",
    "    \n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "045d6252-01c9-4ba2-a114-b2dbecbfc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "bs = 128\n",
    "epochs = 4\n",
    "lr = 8e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ab2418f-8e4f-45c4-b17f-1c06bb940f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0040aa49-fcb3-433d-b948-17ad15555a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9995a93aefd4783bc6e23cb305cd997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz, compute_metrics=corr_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5a159fe-849e-4812-b315-1c2a92039efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, id. If input, target, anchor, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 27354\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [856/856 14:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025698</td>\n",
       "      <td>0.799198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.823025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.023134</td>\n",
       "      <td>0.830327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.022826</td>\n",
       "      <td>0.832513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, id. If input, target, anchor, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, id. If input, target, anchor, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "Saving model checkpoint to outputs/checkpoint-500\n",
      "Configuration saved in outputs/checkpoint-500/config.json\n",
      "Model weights saved in outputs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, id. If input, target, anchor, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, id. If input, target, anchor, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac857edf-45d1-4960-9d22-790a25282a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to microsoft/deberta-v3-small\n",
      "Configuration saved in microsoft/deberta-v3-small/config.json\n",
      "Model weights saved in microsoft/deberta-v3-small/pytorch_model.bin\n",
      "tokenizer config file saved in microsoft/deberta-v3-small/tokenizer_config.json\n",
      "Special tokens file saved in microsoft/deberta-v3-small/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e9bc8fe-60c9-412f-9d93-6496313b3157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, id. If input, target, anchor, context, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 12:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.50732422],\n",
       "       [ 0.71484375],\n",
       "       [ 0.55419922],\n",
       "       [ 0.29467773],\n",
       "       [-0.03997803],\n",
       "       [ 0.49511719],\n",
       "       [ 0.56640625],\n",
       "       [-0.02009583],\n",
       "       [ 0.24560547],\n",
       "       [ 1.06640625],\n",
       "       [ 0.26586914],\n",
       "       [ 0.27563477],\n",
       "       [ 0.78710938],\n",
       "       [ 0.83642578],\n",
       "       [ 0.75146484],\n",
       "       [ 0.43457031],\n",
       "       [ 0.25317383],\n",
       "       [-0.01687622],\n",
       "       [ 0.66455078],\n",
       "       [ 0.34277344],\n",
       "       [ 0.45410156],\n",
       "       [ 0.21435547],\n",
       "       [ 0.0670166 ],\n",
       "       [ 0.23718262],\n",
       "       [ 0.57470703],\n",
       "       [-0.01470184],\n",
       "       [-0.04037476],\n",
       "       [-0.03207397],\n",
       "       [-0.04214478],\n",
       "       [ 0.63867188],\n",
       "       [ 0.43017578],\n",
       "       [ 0.046875  ],\n",
       "       [ 0.73144531],\n",
       "       [ 0.5234375 ],\n",
       "       [ 0.47924805],\n",
       "       [ 0.21081543]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63c9b170-1b4c-4e67-a7d7-826b484c351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.clip(preds, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84a57fe3-9f6c-46ff-bece-1a1ed49466ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50732422],\n",
       "       [0.71484375],\n",
       "       [0.55419922],\n",
       "       [0.29467773],\n",
       "       [0.        ],\n",
       "       [0.49511719],\n",
       "       [0.56640625],\n",
       "       [0.        ],\n",
       "       [0.24560547],\n",
       "       [1.        ],\n",
       "       [0.26586914],\n",
       "       [0.27563477],\n",
       "       [0.78710938],\n",
       "       [0.83642578],\n",
       "       [0.75146484],\n",
       "       [0.43457031],\n",
       "       [0.25317383],\n",
       "       [0.        ],\n",
       "       [0.66455078],\n",
       "       [0.34277344],\n",
       "       [0.45410156],\n",
       "       [0.21435547],\n",
       "       [0.0670166 ],\n",
       "       [0.23718262],\n",
       "       [0.57470703],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.63867188],\n",
       "       [0.43017578],\n",
       "       [0.046875  ],\n",
       "       [0.73144531],\n",
       "       [0.5234375 ],\n",
       "       [0.47924805],\n",
       "       [0.21081543]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fab34225-056a-442f-9003-a65a65431f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5997814c6ff4b6a8e1d01c5bd0c8825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8425c437-e209-4f70-9023-35a853ede5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>opc drum</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "      <td>TEXT1: G02; TEXT2: inorganic photoconductor dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>adjust gas flow</td>\n",
       "      <td>altering gas flow</td>\n",
       "      <td>F23</td>\n",
       "      <td>TEXT1: F23; TEXT2: altering gas flow; ANC1: ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>lower trunnion</td>\n",
       "      <td>lower locating</td>\n",
       "      <td>B60</td>\n",
       "      <td>TEXT1: B60; TEXT2: lower locating; ANC1: lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1f37ead645e7f0c8</td>\n",
       "      <td>cap component</td>\n",
       "      <td>upper portion</td>\n",
       "      <td>D06</td>\n",
       "      <td>TEXT1: D06; TEXT2: upper portion; ANC1: cap co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71a5b6ad068d531f</td>\n",
       "      <td>neural stimulation</td>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>H04</td>\n",
       "      <td>TEXT1: H04; TEXT2: artificial neural network; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id              anchor                         target  \\\n",
       "0  4112d61851461f60            opc drum  inorganic photoconductor drum   \n",
       "1  09e418c93a776564     adjust gas flow              altering gas flow   \n",
       "2  36baf228038e314b      lower trunnion                 lower locating   \n",
       "3  1f37ead645e7f0c8       cap component                  upper portion   \n",
       "4  71a5b6ad068d531f  neural stimulation      artificial neural network   \n",
       "\n",
       "  context                                              input  \n",
       "0     G02  TEXT1: G02; TEXT2: inorganic photoconductor dr...  \n",
       "1     F23  TEXT1: F23; TEXT2: altering gas flow; ANC1: ad...  \n",
       "2     B60  TEXT1: B60; TEXT2: lower locating; ANC1: lower...  \n",
       "3     D06  TEXT1: D06; TEXT2: upper portion; ANC1: cap co...  \n",
       "4     H04  TEXT1: H04; TEXT2: artificial neural network; ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac8599c6-3a36-4124-984c-4e1b6454d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d93fcef824082a3</td>\n",
       "      <td>protocol component</td>\n",
       "      <td>circuit</td>\n",
       "      <td>A46</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9658a68dedd1b4cc</td>\n",
       "      <td>adjacent laterally</td>\n",
       "      <td>radius</td>\n",
       "      <td>A41</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fdd44f80c6009fbd</td>\n",
       "      <td>free fatty acid</td>\n",
       "      <td>sore</td>\n",
       "      <td>C12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8445a426162619dc</td>\n",
       "      <td>hydrocarbyl substituted succinic</td>\n",
       "      <td>dicarboxylic</td>\n",
       "      <td>C10</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eabf6e3ebaeae987</td>\n",
       "      <td>metatarsal bones</td>\n",
       "      <td>metatarsal</td>\n",
       "      <td>A61</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                            anchor        target context  \\\n",
       "0  1d93fcef824082a3                protocol component       circuit     A46   \n",
       "1  9658a68dedd1b4cc                adjacent laterally        radius     A41   \n",
       "2  fdd44f80c6009fbd                   free fatty acid          sore     C12   \n",
       "3  8445a426162619dc  hydrocarbyl substituted succinic  dicarboxylic     C10   \n",
       "4  eabf6e3ebaeae987                  metatarsal bones    metatarsal     A61   \n",
       "\n",
       "   score  \n",
       "0   0.25  \n",
       "1   0.25  \n",
       "2   0.00  \n",
       "3   0.50  \n",
       "4   0.50  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = dds['test'].rename_columns({'labels':'score'}).to_pandas()[['id','anchor','target','context','score']]\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b33b251a-f738-461b-b007-bbac140dc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f2685998ee4452a2390599372d0823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '1d93fcef824082a3',\n",
       " 'anchor': 'protocol component',\n",
       " 'target': 'circuit',\n",
       " 'context': 'A46',\n",
       " 'score': 0.25,\n",
       " 'input': 'TEXT1: A46; TEXT2: circuit; ANC1: protocol component',\n",
       " 'input_ids': [1,\n",
       "  54453,\n",
       "  435,\n",
       "  294,\n",
       "  336,\n",
       "  5718,\n",
       "  346,\n",
       "  54453,\n",
       "  445,\n",
       "  294,\n",
       "  4823,\n",
       "  346,\n",
       "  23702,\n",
       "  435,\n",
       "  294,\n",
       "  6624,\n",
       "  3480,\n",
       "  2],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['input'] = 'TEXT1: ' + valid_df.context + '; TEXT2: ' + valid_df.target + '; ANC1: ' + valid_df.anchor\n",
    "valid_ds = Dataset.from_pandas(valid_df).map(tok_func, batched=True)\n",
    "valid_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1de57783-9adb-4713-ab83-13d1a1181599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: input, target, anchor, context, score, id. If input, target, anchor, context, score, id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 9119\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.3193  ],\n",
       "       [ 0.2573  ],\n",
       "       [-0.010704],\n",
       "       ...,\n",
       "       [ 0.4575  ],\n",
       "       [ 0.524   ],\n",
       "       [ 0.473   ]], dtype=float16), label_ids=None, metrics={'test_runtime': 20.8631, 'test_samples_per_second': 437.087, 'test_steps_per_second': 1.726})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = trainer.predict(valid_ds)\n",
    "valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d3c1dad-4bd4-4442-ae95-9a1617258a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9119"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "valid_pf = valid_preds.predictions.astype(float)\n",
    "valid_pf = np.clip(valid_pf, 0, 1)\n",
    "len(valid_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f817bdc-1e70-4ad0-9b51-3823064116b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['predicted_score'] = valid_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5834da3f-72c8-416e-854e-73692e75c33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>input</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1d93fcef824082a3</td>\n",
       "      <td>protocol component</td>\n",
       "      <td>circuit</td>\n",
       "      <td>A46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXT1: A46; TEXT2: circuit; ANC1: protocol com...</td>\n",
       "      <td>0.319336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9658a68dedd1b4cc</td>\n",
       "      <td>adjacent laterally</td>\n",
       "      <td>radius</td>\n",
       "      <td>A41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>TEXT1: A41; TEXT2: radius; ANC1: adjacent late...</td>\n",
       "      <td>0.257324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fdd44f80c6009fbd</td>\n",
       "      <td>free fatty acid</td>\n",
       "      <td>sore</td>\n",
       "      <td>C12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>TEXT1: C12; TEXT2: sore; ANC1: free fatty acid</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8445a426162619dc</td>\n",
       "      <td>hydrocarbyl substituted succinic</td>\n",
       "      <td>dicarboxylic</td>\n",
       "      <td>C10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXT1: C10; TEXT2: dicarboxylic; ANC1: hydroca...</td>\n",
       "      <td>0.287354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eabf6e3ebaeae987</td>\n",
       "      <td>metatarsal bones</td>\n",
       "      <td>metatarsal</td>\n",
       "      <td>A61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>TEXT1: A61; TEXT2: metatarsal; ANC1: metatarsa...</td>\n",
       "      <td>0.574707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                            anchor        target context  \\\n",
       "0  1d93fcef824082a3                protocol component       circuit     A46   \n",
       "1  9658a68dedd1b4cc                adjacent laterally        radius     A41   \n",
       "2  fdd44f80c6009fbd                   free fatty acid          sore     C12   \n",
       "3  8445a426162619dc  hydrocarbyl substituted succinic  dicarboxylic     C10   \n",
       "4  eabf6e3ebaeae987                  metatarsal bones    metatarsal     A61   \n",
       "\n",
       "   score                                              input  predicted_score  \n",
       "0   0.25  TEXT1: A46; TEXT2: circuit; ANC1: protocol com...         0.319336  \n",
       "1   0.25  TEXT1: A41; TEXT2: radius; ANC1: adjacent late...         0.257324  \n",
       "2   0.00     TEXT1: C12; TEXT2: sore; ANC1: free fatty acid         0.000000  \n",
       "3   0.50  TEXT1: C10; TEXT2: dicarboxylic; ANC1: hydroca...         0.287354  \n",
       "4   0.50  TEXT1: A61; TEXT2: metatarsal; ANC1: metatarsa...         0.574707  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdfc19ee-2976-467b-9960-7273cffa310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14964146302443787"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "MSE = mean_squared_error(y_true = valid_df['score'], y_pred = valid_df['predicted_score'])\n",
    "MSE\n",
    "MSE**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc071290-fd38-42ee-a682-ae4efa362018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
